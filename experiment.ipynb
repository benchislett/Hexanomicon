{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading card data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 34458 cards\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"oracle-cards-20250405210637.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "print(f\"Loaded {len(data)} cards\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_card_data(oracle_data):\n",
    "    if \"mana_cost\" not in oracle_data:\n",
    "        return None\n",
    "    if \"oracle_text\" not in oracle_data:\n",
    "        return None\n",
    "    return {\n",
    "        \"name\": oracle_data[\"name\"],\n",
    "        \"mana_cost\": oracle_data[\"mana_cost\"],\n",
    "        \"cmc\": oracle_data[\"cmc\"],\n",
    "        \"type\": oracle_data[\"type_line\"],\n",
    "        \"text\": oracle_data[\"oracle_text\"],\n",
    "        \"power\": oracle_data.get(\"power\"),\n",
    "        \"toughness\": oracle_data.get(\"toughness\"),\n",
    "        \"loyalty\": oracle_data.get(\"loyalty\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cards_by_name = {card[\"name\"]: get_card_data(card) for card in data}\n",
    "all_cards_by_name = {k: v for k, v in all_cards_by_name.items() if v is not None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select a subset of cards to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A number of classic magic cards\n",
    "sample_cards = [\n",
    "    \"Counterspell\",\n",
    "    \"Mana Drain\",\n",
    "    \"Daze\",\n",
    "    \"Force of Will\",\n",
    "    \"Spell Snare\",\n",
    "    \"Mana Leak\",\n",
    "    \"Remand\",\n",
    "    \"Spell Pierce\",\n",
    "    \"Negate\",\n",
    "    \"Dispel\",\n",
    "    \"Logic Knot\",\n",
    "    \"Dash Hopes\",\n",
    "    \"Dovin's Veto\",\n",
    "    \"Cancel\",\n",
    "    \"Arcane Denial\",\n",
    "    \"Counterbalance\",\n",
    "    \"Doomsday\",\n",
    "    \"Cryptic Command\",\n",
    "    \"Swan Song\",\n",
    "    \"Flusterstorm\",\n",
    "    \"Pact of Negation\",\n",
    "    \"Spell Queller\",\n",
    "    \"Stubborn Denial\",\n",
    "    \"Mystical Dispute\",\n",
    "    \"Disdainful Stroke\",\n",
    "    \"Unwind\",\n",
    "    \"Counterflux\",\n",
    "    \"Narset's Reversal\",\n",
    "    \"Siren Stormtamer\",\n",
    "    \"Mana Tithe\",\n",
    "    \"Sphinx's Revelation\",\n",
    "    \"Dismember\",\n",
    "    \"Swords to Plowshares\",\n",
    "    \"Path to Exile\",\n",
    "    \"Terminate\",\n",
    "    \"Lightning Bolt\",\n",
    "    \"Shock\",\n",
    "]\n",
    "\n",
    "sample_cards = [card for card in sample_cards if card in all_cards_by_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format card data into text descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_card(card_data):\n",
    "    \"\"\"Format a card for input into a vector-embedding model.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "The following is a card from the game Magic: The Gathering.\n",
    "\n",
    "Name: {card_data[\"name\"]}\n",
    "Mana cost: {card_data[\"mana_cost\"]}\n",
    "Converted mana cost: {card_data[\"cmc\"]}\n",
    "Type Line: {card_data[\"type\"]}\n",
    "Oracle text: {card_data[\"text\"]}\n",
    "Power: {card_data[\"power\"]}\n",
    "Toughness: {card_data[\"toughness\"]}\n",
    "Loyalty: {card_data[\"loyalty\"]}\n",
    "\"\"\"\n",
    "    return prompt.strip()\n",
    "\n",
    "formatted_cards = [format_card(all_cards_by_name[card]) for card in sample_cards]\n",
    "postprocessed_formatted_cards = formatted_cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a card from the game Magic: The Gathering.\n",
      "\n",
      "Name: Counterspell\n",
      "Mana cost: {U}{U}\n",
      "Converted mana cost: 2.0\n",
      "Type Line: Instant\n",
      "Oracle text: Counter target spell.\n",
      "Power: None\n",
      "Toughness: None\n",
      "Loyalty: None\n",
      "================================================================================\n",
      "The following is a card from the game Magic: The Gathering.\n",
      "\n",
      "Name: Mana Drain\n",
      "Mana cost: {U}{U}\n",
      "Converted mana cost: 2.0\n",
      "Type Line: Instant\n",
      "Oracle text: Counter target spell. At the beginning of your next main phase, add an amount of {C} equal to that spell's mana value.\n",
      "Power: None\n",
      "Toughness: None\n",
      "Loyalty: None\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "for prompt in formatted_cards[:2]:\n",
    "    print(prompt)\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use an LLM to expand the card descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_postprocessing_prompts(card_descriptions):\n",
    "    prompts = []\n",
    "    for text in card_descriptions:\n",
    "        prompt = f\"\"\"\n",
    "## ROLE\n",
    "You are an expert Magic: the Gathering rules analyst.\n",
    "\n",
    "## TASK\n",
    "Generate compact, retrieval-oriented annotations for the card below.  \n",
    "Return ONLY the JSON object described in *Output schema* (inside a ```json block).  \n",
    "Do **not** repeat the card's rules text or name.\n",
    "\n",
    "## INPUT\n",
    "{text}\n",
    "\"\"\" + \"\"\"\n",
    "## OUTPUT SCHEMA\n",
    "```json\n",
    "{\n",
    "  \"mechanics\": [\"<up to 7 MTG keywords or shorthand, e.g. \\\"ETB\\\", \\\"dies trigger\\\", \\\"lifegain\\\" >\"],\n",
    "  \"roles\":    [\"<card roles: ramp, removal, finisher, toolbox, etc.>\"],\n",
    "  \"strategies\":[\"<decks or archetypes it fits: aristocrats, blink, etc.>\"],\n",
    "  \"synergies\":[\"<key tribes, card types, or mechanics it combines with>\"],\n",
    "  \"power_band\":\"<one of: low | medium | high>\",\n",
    "  \"why_pick\": \"< brief sentence on if, or why players use it >\"\n",
    "}\n",
    "```\n",
    "\"\"\"\n",
    "        prompts.append(prompt.strip())\n",
    "    return prompts\n",
    "\n",
    "postprocessing_prompts = prepare_postprocessing_prompts(formatted_cards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Qwen locally with vLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benchislett/Repos/Hexanomicon/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-23 15:51:07 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 15:51:07,749\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-23 15:51:11 [config.py:689] This model supports multiple tasks: {'score', 'embed', 'generate', 'classify', 'reward'}. Defaulting to 'generate'.\n",
      "INFO 04-23 15:51:11 [config.py:1901] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "INFO 04-23 15:51:12 [core.py:61] Initializing a V1 LLM engine (v0.8.4) with config: model='Qwen/Qwen2.5-7B-Instruct', speculative_config=None, tokenizer='Qwen/Qwen2.5-7B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=fp8, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=Qwen/Qwen2.5-7B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":3,\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":512}\n",
      "WARNING 04-23 15:51:13 [utils.py:2444] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7ef1d56e94c0>\n",
      "INFO 04-23 15:51:13 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 04-23 15:51:13 [cuda.py:221] Using Flash Attention backend on V1 engine.\n",
      "INFO 04-23 15:51:13 [gpu_model_runner.py:1276] Starting to load model Qwen/Qwen2.5-7B-Instruct...\n",
      "WARNING 04-23 15:51:13 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 04-23 15:51:13 [weight_utils.py:265] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:01,  2.85it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:00<00:00,  2.78it/s]\n",
      "Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  2.66it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:01<00:00,  2.63it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:01<00:00,  2.67it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-23 15:51:15 [loader.py:458] Loading weights took 1.54 seconds\n",
      "INFO 04-23 15:51:15 [gpu_model_runner.py:1291] Model loading took 8.1372 GiB and 1.889585 seconds\n",
      "INFO 04-23 15:51:19 [backends.py:416] Using cache directory: /home/benchislett/.cache/vllm/torch_compile_cache/fdfad17ec6/rank_0_0 for vLLM's torch.compile\n",
      "INFO 04-23 15:51:19 [backends.py:426] Dynamo bytecode transform time: 3.94 s\n",
      "INFO 04-23 15:51:21 [backends.py:132] Cache the graph of shape None for later use\n",
      "INFO 04-23 15:51:32 [backends.py:144] Compiling a graph for general shape takes 12.07 s\n",
      "INFO 04-23 15:51:43 [monitor.py:33] torch.compile takes 16.00 s in total\n",
      "INFO 04-23 15:51:44 [kv_cache_utils.py:634] GPU KV cache size: 50,512 tokens\n",
      "INFO 04-23 15:51:44 [kv_cache_utils.py:637] Maximum concurrency for 32,768 tokens per request: 1.54x\n",
      "INFO 04-23 15:52:21 [gpu_model_runner.py:1626] Graph capturing finished in 37 secs, took 0.49 GiB\n",
      "INFO 04-23 15:52:21 [core.py:163] init engine (profile, create kv cache, warmup model) took 65.11 seconds\n",
      "INFO 04-23 15:52:21 [core_client.py:435] Core engine process 0 ready.\n",
      "INFO 04-23 15:52:21 [chat_utils.py:396] Detected the chat template content format to be 'string'. You can set `--chat-template-content-format` to override this.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.56s/it, est. speed input: 4342.67 toks/s, output: 27.37 toks/s]\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "sampling_params = SamplingParams(temperature=0.3, top_p=0.95, max_tokens=512)\n",
    "llm = LLM(model=\"Qwen/Qwen2.5-7B-Instruct\", quantization=\"fp8\")\n",
    "outputs = llm.chat(messages=[{\"role\": \"user\", \"content\": prompt} for prompt in postprocessing_prompts], sampling_params=sampling_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 37/37 [00:02<00:00, 13.17it/s, est. speed input: 4260.25 toks/s, output: 1113.38 toks/s]\n"
     ]
    }
   ],
   "source": [
    "outputs = llm.chat(messages=[[{\"role\": \"user\", \"content\": prompt}] for prompt in postprocessing_prompts], sampling_params=sampling_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a card from the game Magic: The Gathering.\n",
      "\n",
      "Name: Daze\n",
      "Mana cost: {1}{U}\n",
      "Converted mana cost: 2.0\n",
      "Type Line: Instant\n",
      "Oracle text: You may return an Island you control to its owner's hand rather than pay this spell's mana cost.\n",
      "Counter target spell unless its controller pays {1}.\n",
      "Power: None\n",
      "Toughness: None\n",
      "Loyalty: None\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mechanics': ['Instant', 'Counter', 'Return'],\n",
       " 'roles': ['Removal', 'Ramp'],\n",
       " 'strategies': ['Control', 'Blue Weenie'],\n",
       " 'synergies': ['Counterspells', 'Islands', 'Blue Spells'],\n",
       " 'power_band': 'medium',\n",
       " 'why_pick': 'Flexible removal and mana ramp in a single card.'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_output(model_output):\n",
    "    \"\"\"Parse the model output into a JSON object.\"\"\"\n",
    "    try:\n",
    "        model_output = model_output.strip(\"```\").strip(\"json\").strip()\n",
    "        return json.loads(model_output)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Failed to parse JSON: {e}\")\n",
    "        return None\n",
    "\n",
    "print(formatted_cards[2])\n",
    "print('\\n\\n\\n')\n",
    "parse_output(outputs[2].outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## ROLE\n",
      "You are an expert Magic: the Gathering rules analyst.\n",
      "\n",
      "## TASK\n",
      "Generate compact, retrieval-oriented annotations for the card below.  \n",
      "Return ONLY the JSON object described in *Output schema* (inside a ```json block).  \n",
      "Do **not** repeat the card's rules text or name.\n",
      "\n",
      "## INPUT\n",
      "The following is a card from the game Magic: The Gathering.\n",
      "\n",
      "Name: Daze\n",
      "Mana cost: {1}{U}\n",
      "Converted mana cost: 2.0\n",
      "Type Line: Instant\n",
      "Oracle text: You may return an Island you control to its owner's hand rather than pay this spell's mana cost.\n",
      "Counter target spell unless its controller pays {1}.\n",
      "Power: None\n",
      "Toughness: None\n",
      "Loyalty: None\n",
      "\n",
      "## OUTPUT SCHEMA\n",
      "```json\n",
      "{\n",
      "  \"mechanics\": [\"<up to 7 MTG keywords or shorthand, e.g. \"ETB\", \"dies trigger\", \"lifegain\" >\"],\n",
      "  \"roles\":    [\"<card roles: ramp, removal, finisher, toolbox, etc.>\"],\n",
      "  \"strategies\":[\"<decks or archetypes it fits: aristocrats, blink, etc.>\"],\n",
      "  \"synergies\":[\"<key tribes, card types, or mechanics it combines with>\"],\n",
      "  \"power_band\":\"<one of: low | medium | high>\",\n",
      "  \"why_pick\": \"< brief sentence on if, or why players use it >\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(postprocessing_prompts[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished chunk 0\n",
      "out of  4\n",
      "finished chunk 1\n",
      "out of  4\n",
      "finished chunk 2\n",
      "out of  4\n",
      "finished chunk 3\n",
      "out of  4\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "all_embeddings = []\n",
    "\n",
    "chunk_size = 10\n",
    "sleep_time = 2 # seconds between chunk requests\n",
    "\n",
    "for i in range(len(formatted_cards) // chunk_size + 1):\n",
    "    cards = formatted_cards[i * chunk_size:(i + 1) * chunk_size]\n",
    "    if not cards:\n",
    "        break\n",
    "\n",
    "    raise ValueError(\"Watch out, this line is expensive!\")\n",
    "    embeddings = client.models.embed_content(\n",
    "        model=model,\n",
    "        contents=cards,\n",
    "        config=genai.types.EmbedContentConfig(\n",
    "            task_type=\"retrieval_document\",\n",
    "            title=\"MTG card embeddings\"\n",
    "        )\n",
    "    )\n",
    "    for embedding in embeddings.embeddings:\n",
    "        all_embeddings.append(np.array(embedding.values))\n",
    "\n",
    "    print(\"finished chunk\", i)\n",
    "    print(\"out of \", len(formatted_cards) // chunk_size + 1)\n",
    "    time.sleep(sleep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "import chromadb\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Collection [MTGCardsDatabase] already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInternalError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[78]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m chroma_client = chromadb.Client()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m db = \u001b[43mchroma_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMTGCardsDatabase\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m db.add(\n\u001b[32m      6\u001b[39m     documents=formatted_cards,\n\u001b[32m      7\u001b[39m     embeddings=all_embeddings,\n\u001b[32m      8\u001b[39m     ids=sample_cards,\n\u001b[32m      9\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/Hexanomicon/.venv/lib/python3.12/site-packages/chromadb/api/client.py:154\u001b[39m, in \u001b[36mClient.create_collection\u001b[39m\u001b[34m(self, name, configuration, metadata, embedding_function, data_loader, get_or_create)\u001b[39m\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    153\u001b[39m         configuration[\u001b[33m\"\u001b[39m\u001b[33membedding_function\u001b[39m\u001b[33m\"\u001b[39m] = embedding_function\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_server\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Collection(\n\u001b[32m    163\u001b[39m     client=\u001b[38;5;28mself\u001b[39m._server,\n\u001b[32m    164\u001b[39m     model=model,\n\u001b[32m    165\u001b[39m     embedding_function=embedding_function,\n\u001b[32m    166\u001b[39m     data_loader=data_loader,\n\u001b[32m    167\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/Hexanomicon/.venv/lib/python3.12/site-packages/chromadb/api/rust.py:223\u001b[39m, in \u001b[36mRustBindingsAPI.create_collection\u001b[39m\u001b[34m(self, name, configuration, metadata, get_or_create, tenant, database)\u001b[39m\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    221\u001b[39m     configuration_json_str = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m collection = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbindings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfiguration_json_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatabase\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    226\u001b[39m collection_model = CollectionModel(\n\u001b[32m    227\u001b[39m     \u001b[38;5;28mid\u001b[39m=collection.id,\n\u001b[32m    228\u001b[39m     name=collection.name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    235\u001b[39m     database=collection.database,\n\u001b[32m    236\u001b[39m )\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m collection_model\n",
      "\u001b[31mInternalError\u001b[39m: Collection [MTGCardsDatabase] already exists"
     ]
    }
   ],
   "source": [
    "chroma_client = chromadb.Client()\n",
    "db = chroma_client.create_collection(\n",
    "    \"MTGCardsDatabase\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.add(\n",
    "    documents=formatted_cards,\n",
    "    embeddings=all_embeddings,\n",
    "    ids=sample_cards,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "counterspell_index = sample_cards.index(\"Counterspell\")\n",
    "counterspell_embedding = all_embeddings[counterspell_index]\n",
    "res = db.query(\n",
    "    query_embeddings=[counterspell_embedding],\n",
    "    n_results=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = \"A three mana spell that denies the opponent's spell\"\n",
    "query_embedding = client.models.embed_content(\n",
    "    model=model,\n",
    "    contents=[test_query],\n",
    "    config=genai.types.EmbedContentConfig(\n",
    "        task_type=\"retrieval_query\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = np.array(query_embedding.embeddings[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['Arcane Denial',\n",
       "   'Stubborn Denial',\n",
       "   'Counterflux',\n",
       "   'Mystical Dispute',\n",
       "   'Mana Leak',\n",
       "   'Dispel',\n",
       "   'Force of Will',\n",
       "   'Negate',\n",
       "   'Spell Pierce',\n",
       "   'Pact of Negation']],\n",
       " 'embeddings': None,\n",
       " 'documents': [[\"The following is a card from the game Magic: The Gathering.\\n\\n    Name: Arcane Denial\\n    Mana cost: {1}{U}\\n    Converted mana cost: 2.0\\n    Type Line: Instant\\n    Oracle text: Counter target spell. Its controller may draw up to two cards at the beginning of the next turn's upkeep.\\nYou draw a card at the beginning of the next turn's upkeep.\\n    Power: None\\n    Toughness: None\\n    Loyalty: None\",\n",
       "   'The following is a card from the game Magic: The Gathering.\\n\\n    Name: Stubborn Denial\\n    Mana cost: {U}\\n    Converted mana cost: 1.0\\n    Type Line: Instant\\n    Oracle text: Counter target noncreature spell unless its controller pays {1}.\\nFerocious — If you control a creature with power 4 or greater, counter that spell instead.\\n    Power: None\\n    Toughness: None\\n    Loyalty: None',\n",
       "   'The following is a card from the game Magic: The Gathering.\\n\\n    Name: Counterflux\\n    Mana cost: {U}{U}{R}\\n    Converted mana cost: 3.0\\n    Type Line: Instant\\n    Oracle text: This spell can\\'t be countered.\\nCounter target spell you don\\'t control.\\nOverload {1}{U}{U}{R} (You may cast this spell for its overload cost. If you do, change \"target\" in its text to \"each.\")\\n    Power: None\\n    Toughness: None\\n    Loyalty: None',\n",
       "   'The following is a card from the game Magic: The Gathering.\\n\\n    Name: Mystical Dispute\\n    Mana cost: {2}{U}\\n    Converted mana cost: 3.0\\n    Type Line: Instant\\n    Oracle text: This spell costs {2} less to cast if it targets a blue spell.\\nCounter target spell unless its controller pays {3}.\\n    Power: None\\n    Toughness: None\\n    Loyalty: None',\n",
       "   'The following is a card from the game Magic: The Gathering.\\n\\n    Name: Mana Leak\\n    Mana cost: {1}{U}\\n    Converted mana cost: 2.0\\n    Type Line: Instant\\n    Oracle text: Counter target spell unless its controller pays {3}.\\n    Power: None\\n    Toughness: None\\n    Loyalty: None',\n",
       "   'The following is a card from the game Magic: The Gathering.\\n\\n    Name: Dispel\\n    Mana cost: {U}\\n    Converted mana cost: 1.0\\n    Type Line: Instant\\n    Oracle text: Counter target instant spell.\\n    Power: None\\n    Toughness: None\\n    Loyalty: None',\n",
       "   \"The following is a card from the game Magic: The Gathering.\\n\\n    Name: Force of Will\\n    Mana cost: {3}{U}{U}\\n    Converted mana cost: 5.0\\n    Type Line: Instant\\n    Oracle text: You may pay 1 life and exile a blue card from your hand rather than pay this spell's mana cost.\\nCounter target spell.\\n    Power: None\\n    Toughness: None\\n    Loyalty: None\",\n",
       "   'The following is a card from the game Magic: The Gathering.\\n\\n    Name: Negate\\n    Mana cost: {1}{U}\\n    Converted mana cost: 2.0\\n    Type Line: Instant\\n    Oracle text: Counter target noncreature spell.\\n    Power: None\\n    Toughness: None\\n    Loyalty: None',\n",
       "   'The following is a card from the game Magic: The Gathering.\\n\\n    Name: Spell Pierce\\n    Mana cost: {U}\\n    Converted mana cost: 1.0\\n    Type Line: Instant\\n    Oracle text: Counter target noncreature spell unless its controller pays {2}.\\n    Power: None\\n    Toughness: None\\n    Loyalty: None',\n",
       "   \"The following is a card from the game Magic: The Gathering.\\n\\n    Name: Pact of Negation\\n    Mana cost: {0}\\n    Converted mana cost: 0.0\\n    Type Line: Instant\\n    Oracle text: Counter target spell.\\nAt the beginning of your next upkeep, pay {3}{U}{U}. If you don't, you lose the game.\\n    Power: None\\n    Toughness: None\\n    Loyalty: None\"]],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'distances'],\n",
       " 'data': None,\n",
       " 'metadatas': [[None, None, None, None, None, None, None, None, None, None]],\n",
       " 'distances': [[0.5124057531356812,\n",
       "   0.53917396068573,\n",
       "   0.5428659915924072,\n",
       "   0.5429672002792358,\n",
       "   0.5511878728866577,\n",
       "   0.554461658000946,\n",
       "   0.5546119213104248,\n",
       "   0.556618869304657,\n",
       "   0.5587339401245117,\n",
       "   0.5598361492156982]]}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\n",
    "    query_embeddings=[query_embedding],\n",
    "    n_results=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
